{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "plt.rcParams['font.family']='Malgun Gothic' # 한글폰트\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "import scikitplot as skplt\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 불균형데이터의 예측 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사례  ROC < PR 곡선 (불균형자료)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01],\n",
    "                          random_state=1)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='summer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 반반씩 나눠 봄 - stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize dataset\n",
    "print(f'Dataset: Class0={(y==0).sum()}, Class1={(y==1).sum()}')\n",
    "print(f'Train  : Class0={(y_train==0).sum()}, Class1={(y_train==1).sum()}')\n",
    "print(f'Test   : Class0={(y_test==0).sum()}, Class1={(y_test==1).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred   = clf.predict(X_test)\n",
    "y_probas = clf.predict_proba(X_test)\n",
    "\n",
    "target_names = ['Negative(0)', 'Positive(1)']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt \n",
    "skplt.metrics.plot_roc(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.sort(y_probas[:, 1].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_probas 분포\n",
    "#### 한쪽에 몰려 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = y_probas[:, 1]\n",
    "pd.DataFrame(y_scores).hist(bins=100)\n",
    "plt.title('양성판정확률의 분포')\n",
    "plt.xlabel('양성판정확률')\n",
    "np.max(y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(y_scores, columns=['y_predict'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrated_clf = CalibratedClassifierCV(base_estimator=clf, cv=3)\n",
    "calibrated_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_clf.predict_proba(X_train)[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 골고루 균형있게 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yhat = calibrated_clf.predict_proba(X_test)\n",
    "model_probs = yhat[:, 1]\n",
    "pd.DataFrame(model_probs).hist(bins=100)\n",
    "plt.title('양성판정확률의 분포')\n",
    "plt.xlabel('양성판정확률')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['y_predict_calibrated'] = yhat[:, 1]\n",
    "data.hist(figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index().rename(columns={'index':'idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "data.reset_index().plot.scatter(x='index', y='y_predict',            c='red', figsize=(25,4))\n",
    "data.reset_index().plot.scatter(x='index', y='y_predict_calibrated', c='blue', figsize=(25,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/calibration.html#calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced_classification_with_python(by Jason brown)\n",
    "### ROC Curve의 최적 Threshold  찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/imbalanced-classification-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression으로 학습\n",
    "### roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# fit a model\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred   = clf.predict(X_test)\n",
    "y_probas = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y_probas 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_probas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Mean이 최대가 되는 점 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the g-mean for each threshold\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print(f'Best Threshold={thresholds[ix]}, G-mean={gmeans[ix]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve for the model\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='무작위')\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youden’s J statistic을 이용하면 좀더 쉽게 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probas)\n",
    "# get the best threshold\n",
    "J = tpr - fpr\n",
    "ix = np.argmax(J)\n",
    "best_thresh = thresholds[ix]\n",
    "print(f'Best Threshold={best_thresh}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve의 최적 Threshold  찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pr-curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1-score가 가장 커지는 점 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to f-measure\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f-measure\n",
    "ix = np.argmax(fscore)\n",
    "print(f'Best Threshold={thresholds[ix]:.3f}, F-measure={fscore[ix]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Precision-Recall curve for the model\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n",
    "plt.plot(recall, precision, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Threshold Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### threshold 보다 크면 1값을 갖도록 하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y_probas를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "# predict probabilities\n",
    "y_probas = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 threshold 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds\n",
    "thresholds = np.arange(0, 1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1_score를 계산하는 함수를 가지고 threshold에 따라 f1_score 값을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each threshold\n",
    "from sklearn.metrics import f1_score\n",
    "f_scores = [f1_score(y_test, to_labels(y_probas, t)) for t in thresholds]\n",
    "\n",
    "# get best threshold\n",
    "ix = np.argmax(f_scores)\n",
    "print(f'Threshold={thresholds[ix]:.3f}, F-measure={f_scores[ix]:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성과지표 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probas)\n",
    "display(pd.DataFrame(np.vstack([precision, recall]), index=['정밀도', '재현율']).round(2))\n",
    "display(pd.DataFrame(thresholds,columns=['분류임계값']).T.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류임계값에 따라 Positive 판정율 내리는 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [np.sum(to_labels(y_probas, t))/len(y_probas) for t in thresholds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds): \n",
    "    plt.rcParams[\"figure.figsize\"] = (15,6)\n",
    "    plt.rcParams['font.family']='Malgun Gothic' # 한글폰트\n",
    "    plt.title('분류임계값과 (정밀도, 재현율, F1-score, 양성판정비율)', fontsize='16') \n",
    "    plt.plot(thresholds, precisions[:-1], 'b:', label='정밀도(Precision)') # 판사\n",
    "    plt.plot(thresholds, recalls[:-1], 'y-.', label='재현율(Recall)') # 검사\n",
    "    plt.plot(thresholds, (2*precisions[:-1]*recalls[:-1])/(precisions[:-1] +recalls[:-1]), \n",
    "             'r-', label='f1 score(PR조화평균)') # 변호사\n",
    "    plt.plot(thresholds, scores, 'k--', label='양성판정비율') # q-ratio\n",
    "    plt.ylabel('정밀도 /  재현율', fontsize='14') \n",
    "    plt.xlabel('분류임계값', fontsize='14') \n",
    "    plt.legend(loc='best', fontsize='14') \n",
    "    \n",
    "plot_precision_recall_vs_threshold(precision, recall, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 metrics로 Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=y)\n",
    "# fit a model\n",
    "model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': np.logspace(-4, 4, 20), 'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomized = RandomizedSearchCV(model, param_distributions=params, cv=kf, scoring = 'accuracy', random_state=1)\n",
    "y_predict = randomized.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(randomized.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "randomized = RandomizedSearchCV(model, param_distributions=params, cv=kf, scoring = 'recall', random_state=1)\n",
    "y_predict = randomized.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(randomized.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomized = RandomizedSearchCV(model, param_distributions=params, cv=kf, scoring = 'precision', random_state=1)\n",
    "y_predict = randomized.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(randomized.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomized = RandomizedSearchCV(model, param_distributions=params, cv=kf, scoring = 'f1', random_state=1)\n",
    "y_predict = randomized.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(randomized.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "randomized = RandomizedSearchCV(model, param_distributions=params, cv=kf, scoring = ftwo_scorer, random_state=1)\n",
    "y_predict = randomized.fit(X_train, y_train).predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(randomized.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train과정의 값이 잘 맞는 것과 test set에 적용한 결과는 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, randomized.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
