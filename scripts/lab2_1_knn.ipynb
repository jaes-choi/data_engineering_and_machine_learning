{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1609995971856,
     "user": {
      "displayName": "sanggoo cho",
      "photoUrl": "",
      "userId": "05013997244878666178"
     },
     "user_tz": -540
    },
    "id": "iEPTmys-Ozmh"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1609995971856,
     "user": {
      "displayName": "sanggoo cho",
      "photoUrl": "",
      "userId": "05013997244878666178"
     },
     "user_tz": -540
    },
    "id": "iEPTmys-Ozmh"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1992,
     "status": "ok",
     "timestamp": 1609995971856,
     "user": {
      "displayName": "sanggoo cho",
      "photoUrl": "",
      "userId": "05013997244878666178"
     },
     "user_tz": -540
    },
    "id": "iEPTmys-Ozmh"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  K-Nearest Neighbors Classification\n",
    "### 1 Digits Classification Exercise\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/exercises/plot_digits_classification_exercise.html#sphx-glr-auto-examples-exercises-plot-digits-classification-exercise-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_digits, y_digits = datasets.load_digits(return_X_y=True)\n",
    "X_digits = X_digits / X_digits.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 나중에 비교해 볼 것\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc_X = StandardScaler()\n",
    "# X_digits = sc_X.fit_transform(X_digits,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(X_digits)\n",
    "cut_idx = int(.9 * n_samples)\n",
    "\n",
    "X_train = X_digits[:cut_idx]\n",
    "y_train = y_digits[:cut_idx]\n",
    "X_test  = X_digits[cut_idx:]\n",
    "y_test  = y_digits[cut_idx:]\n",
    "\n",
    "knn      = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression(max_iter=1000)\n",
    "\n",
    "print(f'KNN score               : {knn.fit(X_train, y_train).score(X_test, y_test)}')\n",
    "print(f'LogisticRegression score: {logistic.fit(X_train, y_train).score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Step by Step Diabetes Classification-KNN-detailed\n",
    "https://www.kaggle.com/shrutimechlearn/step-by-step-diabetes-classification-knn-detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "diabetes_data = pd.read_csv('../data/diabetes.csv')\n",
    "#Print the first 5 rows of the dataframe.\n",
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_quailty(df) :\n",
    "    tf = pd.DataFrame({'데이터형태(dtypes)' : df.dtypes,\n",
    "                       '비 결측치 수(notnull)': df.notnull().sum(),\n",
    "                       '결측치 수(null)' : df.isnull().sum(),\n",
    "                       '고유값 수(nunique)' : df.nunique()})\n",
    "    return tf\n",
    "\n",
    "df_quailty(diabetes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diabetes_data.hist(figsize = (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))  \n",
    "sns.heatmap(diabetes_data.corr(), annot=True,cmap ='Blues')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### heatmap 대신 간단히 사용할 수 있는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.corr().style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_data.drop([\"Outcome\"],axis = 1)\n",
    "y = diabetes_data.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y, random_state=11)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist= dict(n_neighbors = list(range(5,105, 2)),\n",
    "                 weights     = ['uniform','distance'],\n",
    "                 algorithm   = ['ball_tree', 'kd_tree'],\n",
    "                 leaf_size   = list(range(5,50)))\n",
    "np.random.seed(1357)\n",
    "\n",
    "randomized = RandomizedSearchCV(KNeighborsClassifier(), \n",
    "                                param_distributions= param_dist, cv=kf,\n",
    "                                n_iter=64, scoring= 'recall', verbose=True)\n",
    "randomized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'optimal train score: {randomized.best_score_:.3f}') \n",
    "print(f'test score         : {randomized.score(X_test, y_test):.3f}')\n",
    "print(f'optimal parameter  : {randomized.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X = pd.DataFrame(sc_X.fit_transform(diabetes_data.drop([\"Outcome\"],axis = 1),),\n",
    "                 columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "                          'BMI', 'DiabetesPedigreeFunction', 'Age'])\n",
    "y = diabetes_data.Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    stratify=y, random_state=11)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist= dict(n_neighbors = list(range(5,105, 2)),\n",
    "                 weights     = ['uniform','distance'],\n",
    "                 algorithm   = ['ball_tree', 'kd_tree'],\n",
    "                 leaf_size   = list(range(5,50)))\n",
    "np.random.seed(1357)\n",
    "\n",
    "randomized = RandomizedSearchCV(KNeighborsClassifier(), \n",
    "                                param_distributions= param_dist, cv=kf,\n",
    "                                n_iter=64, scoring= 'recall', verbose=True)\n",
    "randomized.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'optimal train score: {randomized.best_score_:.3f}') \n",
    "print(f'test score         : {randomized.score(X_test, y_test):.3f}')\n",
    "print(f'optimal parameter  : {randomized.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(randomized.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(randomized.cv_results_)[['params', 'mean_test_score', 'rank_test_score']]\n",
    "results.sort_values('rank_test_score').round(4).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "sns.reset_defaults()\n",
    "plot_confusion_matrix(randomized, X_test, y_test)\n",
    "y_pred = randomized.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt \n",
    "y_probas = randomized.predict_proba(X_test)\n",
    "skplt.metrics.plot_roc(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "T = np.linspace(0, 5, 500).reshape(-1,1)\n",
    "y = np.sin(X).reshape(-1,)\n",
    "\n",
    "# noise 넣기\n",
    "y[::5] += (0.5 - np.random.rand(8))\n",
    "\n",
    "\n",
    "# neighbour 개수와 weight 변화시키며 regression model 적합 결과\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,6))\n",
    "\n",
    "for i, weights in enumerate(['uniform', 'distance']):\n",
    "    for j, n_neighbors in enumerate([3, 5]):\n",
    "        knn = neighbors.KNeighborsRegressor(n_neighbors, weights=weights)\n",
    "        y_ = knn.fit(X, y).predict(T)\n",
    "\n",
    "        axes[i,j].scatter(X, y, color='darkorange', label='data')\n",
    "        axes[i,j].plot(T, y_, color='navy', label='prediction')\n",
    "        axes[i,j].axis('tight')\n",
    "        axes[i,j].legend()\n",
    "        axes[i,j].title.set_text(f\"KNeighborsRegressor (k = {n_neighbors}, weights = '{weights}')\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "X = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\n",
    "X\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
